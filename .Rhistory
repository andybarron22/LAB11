import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
# ------------------------------
# Data Import & Cleaning
# ------------------------------
# Load the dataset (ensure "ameshousing.xlsx" is in your working directory)
df = pd.read_excel("Ameshousing.xlsx")
# Fill missing values: use mean for numeric columns and mode for non-numeric columns
for col in df.columns:
if df[col].dtype in [np.float64, np.int64]:
df[col] = df[col].fillna(df[col].mean())
else:
df[col] = df[col].fillna(df[col].mode()[0])
# One-hot encode categorical variables
df = pd.get_dummies(df)
# Normalize numeric features using StandardScaler
numeric_cols = df.select_dtypes(include=[np.number]).columns
scaler = StandardScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])
# ------------------------------
# Feature Selection
# ------------------------------
# Define target and select features with a correlation greater than 0.3 with "SalePrice"
target = 'SalePrice'
correlations = df.corr()[target].abs()
features_to_use = correlations[correlations > 0.3].index.drop(target)
df = df[list(features_to_use) + [target]]
# ------------------------------
# Data Splitting
# ------------------------------
# Separate features and target arrays
X = df.drop(target, axis=1).values.astype(np.float32)
y = df[target].values.astype(np.float32).reshape(-1, 1)
# Split data: 70% training, 15% validation, 15% testing
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)
# Convert numpy arrays to PyTorch tensors
X_train_tensor = torch.tensor(X_train)
y_train_tensor = torch.tensor(y_train)
X_val_tensor   = torch.tensor(X_val)
y_val_tensor   = torch.tensor(y_val)
X_test_tensor  = torch.tensor(X_test)
y_test_tensor  = torch.tensor(y_test)
# ------------------------------
# Build & Train the PyTorch Model
# ------------------------------
# Define model architecture
input_dim = X_train.shape[1]
model = nn.Sequential(
nn.Linear(input_dim, 64),
nn.ReLU(),
nn.Linear(64, 32),
nn.ReLU(),
nn.Linear(32, 1)
)
# Define loss function and optimizer
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
num_epochs = 50
train_losses, val_losses = [], []
# Training loop
for epoch in range(num_epochs):
model.train()
optimizer.zero_grad()
predictions_train = model(X_train_tensor)
loss_train = criterion(predictions_train, y_train_tensor)
loss_train.backward()
optimizer.step()
train_losses.append(loss_train.item())
# Validation step
model.eval()
with torch.no_grad():
loss_val = criterion(model(X_val_tensor), y_val_tensor)
val_losses.append(loss_val.item())
print(f"Epoch {epoch+1}/{num_epochs} - Train Loss: {loss_train.item():.4f}, Val Loss: {loss_val.item():.4f}")
# Test evaluation
model.eval()
with torch.no_grad():
test_loss = criterion(model(X_test_tensor), y_test_tensor)
print("Test MSE:", test_loss.item())
# Plot training and validation loss curves
plt.plot(train_losses, label="Train Loss")
plt.plot(val_losses, label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("MSE")
plt.legend()
plt.title("Loss Curves")
plt.show()
# ------------------------------
# Save & Inference
# ------------------------------
# Save the model's state dictionary
torch.save(model.state_dict(), "housing_price_model.pth")
# Re-create the model architecture and load the saved state
loaded_model = nn.Sequential(
nn.Linear(input_dim, 64),
nn.ReLU(),
nn.Linear(64, 32),
nn.ReLU(),
nn.Linear(32, 1)
)
loaded_model.load_state_dict(torch.load("housing_price_model.pth"))
loaded_model.eval()
# Make predictions on a sample of the test set
sample_input = torch.tensor(X_test[:5])
with torch.no_grad():
sample_predictions = loaded_model(sample_input)
print("Predictions on sample data:")
print(sample_predictions)
setwd("C:/Users/andyc/Downloads/AMES Housing")
reticulate::repl_python()
setwd("C:/Users/andyc/Downloads")
setwd("C:/Users/andyc/Downloads/ICP")
setwd("C:/Users/andyc/Downloads/ICP")
setwd("C:/Users/andyc/Downloads/ICP")
install.packages("pandas")
reticulate::repl_python()
setwd("C:/Users/andyc/Downloads/lab 11 working directory")
reticulate::repl_python()
